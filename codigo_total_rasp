import torch
import torchvision.transforms as transforms
from PIL import Image
import torchvision.models as models
import torch.nn as nno
import time
import io
import tkinter as tk
from tkinter import Label, Button, Frame
from picamera import PiCamera
from picamera.array import PiRGBArray
import numpy as np

# Configuração da câmera do Raspberry Pi
camera = PiCamera()
camera.resolution = (224, 224)  # Resolução da imagem ajustada
camera.framerate = 10  # Reduzindo o framerate para aliviar o processador

# Função para capturar uma imagem da câmera
def capture_frame():
    raw_capture = PiRGBArray(camera)
    camera.capture(raw_capture, format="rgb")
    image = raw_capture.array
    image = Image.fromarray(image)  # Converter para PIL Image
    return image

# Carregar o modelo MobileNetV2 (versão mais leve para Raspberry Pi)
loaded_model = models.mobilenet_v2(pretrained=False)  # MobileNetV2 é mais leve
loaded_model.features[0][0] = nno.Conv2d(1, loaded_model.features[0][0].out_channels, kernel_size=3, stride=2, padding=1, bias=False)
num_classes = 2
loaded_model.classifier[1] = nno.Linear(loaded_model.classifier[1].in_features, num_classes)

# Carregar pesos pré-treinados
model_state = torch.load('Modelo_test2.pth', map_location=torch.device('cpu'))
del model_state['classifier.1.weight']
del model_state['classifier.1.bias']
loaded_model.load_state_dict(model_state, strict=False)
loaded_model = loaded_model.to(torch.device('cpu'))
loaded_model.eval()

# Transformação da imagem para o modelo
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((1,), (1,))
])

# Função para realizar a inferência em tempo real
def infer_real_time():
    while True:
        img = capture_frame()  # Captura imagem da câmera
        img_tensor = transform(img).unsqueeze(0).to(torch.device('cpu'))
        
        start_time = time.time()
        with torch.no_grad():
            output = loaded_model(img_tensor)
            _, predicted = torch.max(output.data, 1)
        end_time = time.time()

        classes = ['Fogo', 'Nao fogo']
        predicted_class = classes[predicted.item()]
        inference_time = end_time - start_time

        label_result.config(text=f'Classe prevista: {predicted_class}\nTempo de inferência: {inference_time:.4f} segundos')
        root.update()  # Atualiza a interface após cada inferência

# Função para fechar o programa
def close_program():
    root.destroy()

# Configuração da interface gráfica
root = tk.Tk()
root.title("Inferência de Imagem com MobileNetV2")
root.geometry("600x400")
root.configure(bg="#f0f0f0")  # Cor de fundo

# Frames para melhor layout
frame_top = Frame(root, bg="#f0f0f0")
frame_top.place(x=10, y=10)

# Caixa de texto "EcoFlight"
label_ecoflight = Label(frame_top, text="EcoFlight", font=("Arial", 16, "bold"), bg="#f0f0f0")
label_ecoflight.pack(side=tk.LEFT)

# Caixa de texto com o nome do modelo
label_model = Label(frame_top, text="Modelo: MobileNetV2", font=("Arial", 12), bg="#f0f0f0")
label_model.pack(side=tk.LEFT, padx=20)

# Botão de iniciar inferência
infer_button = Button(root, text="Iniciar Inferência", command=infer_real_time, bg="#007BFF", fg="white", font=("Arial", 12), padx=10, pady=5)
infer_button.pack(pady=10)

# Botão para fechar o programa
close_button = Button(root, text="Fechar", command=close_program, bg="#FF6347", fg="white", font=("Arial", 12), padx=10, pady=5)
close_button.pack(pady=10)

# Resultado da inferência
label_result = Label(root, text="", wraplength=400, bg="#f0f0f0", font=("Arial", 14))
label_result.pack(pady=20)

root.mainloop()
